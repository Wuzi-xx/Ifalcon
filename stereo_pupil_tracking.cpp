#include <stdio.h>
#include <stdlib.h>
#include <string.h>
#include <fcntl.h>
#include <unistd.h>
#include <termios.h>
#include <errno.h>
#include <sys/ioctl.h>
#include <linux/videodev2.h>
#include <sys/mman.h>
#include <linux/input.h>
#include <poll.h>
#include <thread>
#include <atomic>
#include <opencv2/opencv.hpp>

/********************** 参数定义区 *************************/
#define WIDTH 640             // 图像宽度
#define HEIGHT 480            // 图像高度
#define THRESH_MIN 0          // 阈值下限（备用）
#define THRESH_MAX 40         // 阈值上限（用于二值化）
#define MIN_AREA 1500         // 最小瞳孔轮廓面积
#define CENTER_X (WIDTH / 2)  // 图像中心X
#define CENTER_Y (HEIGHT / 2) // 图像中心Y

/********************** 缓冲区结构体 ************************/
struct buffer {
    void *start;              // 映射到用户空间的内存地址
    size_t length;            // 缓冲区大小
};

std::atomic<bool> g_running(true);  // 全局运行标志，用于控制主循环退出

/**
 * 函数名: monitor_key_event
 * 功能: 监听 Linux 输入事件设备 /dev/input/event1，
 *       当检测到按键按下事件 (EV_KEY, value=1) 时，
 *       修改全局标志 g_running = false，从而通知主线程安全退出程序。
 *
 * 使用场景:
 *   - 在 RV1106 等嵌入式系统中，按键通常映射为 /dev/input/eventX 设备；
 *   - 本线程独立运行，实时监听按键输入；
 *   - 当用户按下指定按键后，终止主循环，关闭摄像头与串口。
 *
 * 参数: 无（通过全局变量 g_running 与主线程通信）
 * 返回值: 无（通过原子变量改变运行状态）
 */
void monitor_key_event() {
    // 打开输入事件设备文件（只读模式）
    // Linux 中所有输入事件（按键、触摸屏、鼠标等）都以 event 设备节点形式存在于 /dev/input 目录下。
    int evfd = open("/dev/input/event1", O_RDONLY);
    if (evfd < 0) {
        // 若打开失败（文件不存在或权限不足），输出错误信息并返回。
        perror("open /dev/input/event1 failed");
        return;
    }

    struct input_event ev;  // 定义输入事件结构体，用于存储每次读取的按键信息

    // 主监听循环：只要全局变量 g_running 为 true，就持续读取事件。
    while (g_running) {
        // read() 从设备文件中读取一个完整的 input_event 结构体
        int rd = read(evfd, &ev, sizeof(ev));

        // 若成功读取到一个完整事件（长度一致），则进行事件类型判断
        if (rd == sizeof(ev)) {
            // EV_KEY 表示键盘或按键事件，ev.value = 1 表示“按下”动作
            if (ev.type == EV_KEY && ev.value == 1) {
                printf("[KEY] Button pressed, exiting...\n");

                // 设置全局运行标志为 false，通知主循环安全退出
                g_running = false;

                // 跳出监听循环（同时结束该线程）
                break;
            }
        }
        // 如果 read() 读取异常（例如被信号中断），则下次循环继续监听。
    }

    // 关闭输入设备文件，释放资源
    close(evfd);
}

/**
 * 函数名: detect_pupil
 * 功能: 从单帧图像中检测瞳孔的中心点位置（像素坐标）。
 *
 * 算法流程:
 *   1. 将输入图像转为灰度；
 *   2. 通过阈值分割反转得到黑色瞳孔区域；
 *   3. 提取所有轮廓并计算面积、圆度；
 *   4. 筛选出最接近中心且近似圆形的轮廓；
 *   5. 计算该轮廓的几何中心并返回。
 *
 * 参数:
 *   img - 输入帧 (OpenCV BGR 格式图像)
 *
 * 返回值:
 *   cv::Point(x, y) - 瞳孔中心坐标；若检测失败则返回 (-1, -1)
 */
cv::Point detect_pupil(cv::Mat &img) {
    cv::Mat gray, binary;

    /************************************************************
     * Step 1: 转灰度图像
     * 原图为 BGR 彩色帧，瞳孔检测只关心亮度信息；
     * 因此通过 cvtColor() 转换为单通道灰度图。
     ************************************************************/
    cv::cvtColor(img, gray, cv::COLOR_BGR2GRAY);

    /************************************************************
     * Step 2: 阈值分割 (二值化)
     * 使用 THRESH_BINARY_INV 模式，将低亮度（黑色）区域
     * 转换为白色 (255)，背景变为黑色 (0)，方便后续轮廓提取。
     *
     * 参数解释:
     *   THRESH_MAX = 40 → 灰度值小于40的像素视为瞳孔
     *   255 → 白色输出值
     ************************************************************/
    cv::threshold(gray, binary, THRESH_MAX, 255, cv::THRESH_BINARY_INV);

    /************************************************************
     * Step 3: 提取所有轮廓
     * 使用 cv::findContours() 提取外轮廓，忽略内层结构。
     * 结果为一个二维 vector，每个轮廓由一系列点构成。
     ************************************************************/
    std::vector<std::vector<cv::Point>> contours;
    cv::findContours(binary, contours, cv::RETR_EXTERNAL, cv::CHAIN_APPROX_SIMPLE);

    /************************************************************
     * Step 4: 初始化最优瞳孔参数
     *   best_center → 最优瞳孔的中心坐标
     *   min_dist2 → 当前最接近图像中心的瞳孔距离平方
     ************************************************************/
    cv::Point best_center(-1, -1);
    double min_dist2 = DBL_MAX;
    std::vector<cv::Point> best_contour;

    /************************************************************
     * Step 5: 遍历所有轮廓，筛选出最符合条件的瞳孔
     ************************************************************/
    for (const auto &cnt : contours) {
        /******************* (1) 面积筛选 *******************
         * 忽略过小的区域（如噪声点、反光点等）
         * MIN_AREA 在宏定义中设置为 1500 像素
         ************************************************************/
        double area = cv::contourArea(cnt);
        if (area < MIN_AREA) continue;

        /******************* (2) 周长计算 *******************
         * arcLength() 返回闭合轮廓的长度；
         * 若为零（异常轮廓），跳过。
         ************************************************************/
        double perimeter = cv::arcLength(cnt, true);
        if (perimeter == 0) continue;

        /******************* (3) 圆度判定 *******************
         * 圆度 circularity = 4πA / P²
         * 理想圆形 circularity = 1；
         * 若 < 0.7，则认为形状不够圆，不是瞳孔。
         ************************************************************/
        double circularity = 4 * CV_PI * area / (perimeter * perimeter);
        if (circularity < 0.7) continue;

        /******************* (4) 计算质心 *******************
         * 使用图像矩求出几何中心：
         *   cx = M10 / M00, cy = M01 / M00
         ************************************************************/
        cv::Moments M = cv::moments(cnt);
        if (M.m00 == 0) continue;
        int cx = static_cast<int>(M.m10 / M.m00);
        int cy = static_cast<int>(M.m01 / M.m00);

        /******************* (5) 中心偏移度判断 *******************
         * 计算该轮廓中心与图像中心的欧式距离平方；
         * 取距离最小者作为最终瞳孔区域。
         ************************************************************/
        double dist2 = (cx - CENTER_X) * (cx - CENTER_X) + (cy - CENTER_Y) * (cy - CENTER_Y);

        if (dist2 < min_dist2) {
            min_dist2 = dist2;
            best_center = cv::Point(cx, cy);
            best_contour = cnt;
        }
    }

    /************************************************************
     * Step 6: 若检测到有效瞳孔，绘制辅助标记
     ************************************************************/
    if (!best_contour.empty()) {
        float radius;
        cv::Point2f enclosing_center;

        // 用最小外接圆包围该轮廓，估计瞳孔边界半径
        cv::minEnclosingCircle(best_contour, enclosing_center, radius);

        // 绘制十字中心标记 (绿色)
        cv::drawMarker(img, best_center, cv::Scalar(0, 255, 0),
                       cv::MARKER_CROSS, 10, 2);

        // 绘制圆形边界线 (红色)
        cv::circle(img, enclosing_center,
                   static_cast<int>(radius), cv::Scalar(0, 0, 255), 2);

        // 返回检测到的瞳孔中心坐标
        return best_center;
    }

    /************************************************************
     * Step 7: 若未检测到瞳孔，返回无效坐标 (-1, -1)
     ************************************************************/
    return cv::Point(-1, -1);
}

/**
 * 函数名: triangulate
 * 功能: 根据左右相机中检测到的瞳孔像素坐标，计算瞳孔在三维空间中的坐标 (X, Y, Z)
 *
 * 算法原理:
 *   - 基于双目视觉几何模型（立体三角测量）；
 *   - 已知两台摄像机的内参 (K1, K2) 和相对位姿 (R, T)；
 *   - 将像素坐标 (u1,v1)、(u2,v2) 转换为归一化坐标 (x1,y1)、(x2,y2)；
 *   - 计算两条视线（射线）的最近点，作为空间点的估计位置。
 *
 * 数学模型:
 *   左相机射线:  L1(s) = s * r1
 *   右相机射线:  L2(t) = R * (t * r2) + T
 *   其中:
 *      - r1, r2 为两相机的单位方向向量
 *      - R, T 为右相机相对于左相机的旋转矩阵和平移向量
 *   通过最小化两条射线的距离，求得最佳交点近似位置。
 *
 * 参数:
 *   pt1 - 左相机图像中的瞳孔中心坐标 (像素坐标)
 *   pt2 - 右相机图像中的瞳孔中心坐标 (像素坐标)
 *
 * 返回值:
 *   cv::Point3f(X, Y, Z) - 瞳孔的三维坐标（以左相机为世界坐标系原点）
 */
cv::Point3f triangulate(const cv::Point2f &pt1, const cv::Point2f &pt2) {
    /************************************************************
     * Step 1: 定义相机内参 (K1, K2)
     * 参数来源: Matlab 双目标定 (stereoParams.mat)
     * 含义:
     *   fx, fy → 焦距（像素）
     *   cx, cy → 主点坐标（光轴中心）
     ************************************************************/
    double fx1 = 475.8266, fy1 = 477.8292, cx1 = 356.0519, cy1 = 272.4657; // 左相机
    double fx2 = 483.0534, fy2 = 484.4886, cx2 = 375.5120, cy2 = 276.3651; // 右相机

    /************************************************************
     * Step 2: 外参（相对位姿）
     * R: 右相机坐标系相对于左相机坐标系的旋转矩阵
     * T: 右相机坐标系相对于左相机坐标系的平移向量 (单位: mm 或 cm)
     ************************************************************/
    cv::Matx33d R(
            0.999313,  0.036906, -0.003363,
            -0.036555,  0.996563,  0.074340,
            0.006095, -0.074166,  0.997227
    );
    cv::Vec3d T(-0.074773, -12.877214, -0.31784);  // 平移向量

    /************************************************************
     * Step 3: 像素坐标 → 归一化坐标（去除相机内参影响）
     * 公式:
     *   x = (u - cx) / fx
     *   y = (v - cy) / fy
     * 意义: 将像素坐标投影到单位成像平面 (Z=1) 上
     ************************************************************/
    double x1 = (pt1.x - cx1) / fx1;
    double y1 = (pt1.y - cy1) / fy1;
    double x2 = (pt2.x - cx2) / fx2;
    double y2 = (pt2.y - cy2) / fy2;

    /************************************************************
     * Step 4: 构造两条射线方向向量
     *   左相机射线: ray1 = normalize([x1, y1, 1])
     *   右相机射线: ray2 = R * normalize([x2, y2, 1])
     *
     * normalize() 保证向量单位化，表示方向而非距离。
     ************************************************************/
    cv::Vec3d ray1 = cv::normalize(cv::Vec3d(x1, y1, 1.0));       // 左相机光线
    cv::Vec3d ray2 = R * cv::normalize(cv::Vec3d(x2, y2, 1.0));   // 将右相机光线旋转至左相机坐标系下

    /************************************************************
     * Step 5: 计算射线交点（或最近点）
     *   公式:
     *      d = ray1·ray2
     *      s = (T·(ray1 - d*ray2)) / (1 - d²)
     *   推导思路:
     *      使两条射线间的最短距离最小，
     *      以左相机射线的参数 s 对应的点作为空间点估计。
     ************************************************************/
    cv::Vec3d delta_p = T;          // 右相机相对左相机的平移
    double d = ray1.dot(ray2);      // 两射线夹角的余弦值
    double s = delta_p.dot(ray1 - d * ray2) / (1 - d * d);  // 左射线参数解
    cv::Vec3d X = s * ray1;         // 三维空间点坐标（左相机坐标系下）

    /************************************************************
     * Step 6: 输出结果
     * 返回三维点坐标 (X, Y, Z)
     * 单位取决于标定时 T 的单位（一般为毫米或厘米）
     ************************************************************/
    return cv::Point3f(X[0], X[1], X[2]);
}

/**
 * 函数名: init_camera
 * 功能: 初始化指定的视频设备节点（如 /dev/video21、/dev/video23），
 *       配置图像格式、申请缓冲区、完成内存映射，并启动视频流采集。
 *
 * 适用平台:
 *   - Linux 系统 (V4L2 视频采集接口)
 *   - 例如 RV1106、RK3566 等嵌入式主控平台
 *
 * 参数:
 *   devname - 摄像头设备文件路径 (如 "/dev/video21")
 *   buffers - 用于存储内存映射后的缓冲区数组指针
 *   vfd     - 摄像头设备文件描述符 (通过引用返回)
 *
 * 返回值:
 *   返回成功申请的缓冲区数量（通常为2）
 *
 * 主要流程:
 *   1. 打开摄像头设备；
 *   2. 配置图像格式 (分辨率、像素格式等)；
 *   3. 申请缓冲区；
 *   4. 执行 mmap() 建立内存映射；
 *   5. 启动视频流 (STREAMON)。
 */
int init_camera(const char *devname, buffer *buffers, int &vfd) {

    /************************************************************
     * Step 1: 打开摄像头设备文件
     *
     * O_RDWR → 可读可写；
     * 若打开失败（返回 -1），输出错误并终止程序。
     ************************************************************/
    vfd = open(devname, O_RDWR);
    if (vfd < 0) {
        perror("Failed to open camera");
        exit(1);
    }

    /************************************************************
     * Step 2: 设置视频采集格式 (VIDIOC_S_FMT)
     *
     * V4L2_BUF_TYPE_VIDEO_CAPTURE → 视频采集类型；
     * 分辨率: WIDTH × HEIGHT；
     * 像素格式: YUYV (即 YUV422 格式)，每 4 字节代表两个像素；
     * field: NONE → 逐行扫描 (非隔行)。
     ************************************************************/
    struct v4l2_format fmt = {};
    fmt.type = V4L2_BUF_TYPE_VIDEO_CAPTURE;
    fmt.fmt.pix.width = WIDTH;
    fmt.fmt.pix.height = HEIGHT;
    fmt.fmt.pix.pixelformat = V4L2_PIX_FMT_YUYV;
    fmt.fmt.pix.field = V4L2_FIELD_NONE;

    // 将格式设置写入设备
    ioctl(vfd, VIDIOC_S_FMT, &fmt);

    /************************************************************
     * Step 3: 申请视频缓冲区 (VIDIOC_REQBUFS)
     *
     * 说明:
     *   - count = 2 → 系统为该设备申请两个帧缓冲；
     *   - memory = MMAP → 使用内存映射方式；
     *   - 驱动分配内核缓冲，用户程序通过 mmap() 访问。
     ************************************************************/
    struct v4l2_requestbuffers req = {};
    req.count = 2;  // 通常双缓冲即可实现连续采集
    req.type = V4L2_BUF_TYPE_VIDEO_CAPTURE;
    req.memory = V4L2_MEMORY_MMAP;
    ioctl(vfd, VIDIOC_REQBUFS, &req);

    /************************************************************
     * Step 4: 遍历每个缓冲区，执行 QUERYBUF + MMAP + QBUF 操作
     *
     * QUERYBUF → 查询缓冲区信息；
     * MMAP → 将驱动分配的缓冲区映射到用户空间；
     * QBUF → 将缓冲区放入驱动的输入队列，准备采集。
     ************************************************************/
    for (int i = 0; i < req.count; i++) {
        struct v4l2_buffer buf = {};
        buf.type = V4L2_BUF_TYPE_VIDEO_CAPTURE;
        buf.memory = V4L2_MEMORY_MMAP;
        buf.index = i;

        // 查询第 i 个缓冲区的偏移量与长度
        ioctl(vfd, VIDIOC_QUERYBUF, &buf);

        // 记录缓冲区长度
        buffers[i].length = buf.length;

        /********************************************************
         * mmap() 内存映射
         * 将内核空间的视频缓冲区映射到用户空间；
         * 这样可以避免数据拷贝，提高帧采集效率。
         ********************************************************/
        buffers[i].start = mmap(
                NULL,                     // 自动选择映射地址
                buf.length,               // 映射长度
                PROT_READ | PROT_WRITE,   // 可读写
                MAP_SHARED,               // 共享映射
                vfd,                      // 文件描述符
                buf.m.offset              // 缓冲区偏移
        );

        // 检查映射结果
        if (buffers[i].start == MAP_FAILED) {
            perror("mmap failed");
            exit(1);
        }

        // 将缓冲区加入视频输入队列 (即可用于采集)
        ioctl(vfd, VIDIOC_QBUF, &buf);
    }

    /************************************************************
     * Step 5: 启动视频流采集 (VIDIOC_STREAMON)
     *
     * 通知驱动开始捕获帧；
     * 成功后即可通过 DQBUF / QBUF 获取帧数据。
     ************************************************************/
    enum v4l2_buf_type type = V4L2_BUF_TYPE_VIDEO_CAPTURE;
    ioctl(vfd, VIDIOC_STREAMON, &type);

    // 返回缓冲区数量，供后续使用
    return req.count;
}

/**
 * 函数名: capture_frame
 * 功能: 从指定摄像头中读取一帧图像数据，并将其从 YUYV 格式转换为 BGR 格式（OpenCV 可用格式）
 *
 * 调用时机:
 *   - 在主循环中反复调用，用于实时抓取每帧图像。
 *
 * 参数:
 *   vfd     - 摄像头文件描述符（由 init_camera() 初始化返回）
 *   buffers - 已映射的摄像头缓冲区数组指针（存放帧数据）
 *
 * 返回值:
 *   cv::Mat - OpenCV 格式的 BGR 图像帧，可直接用于显示或算法处理
 *
 * 采集流程:
 *   1. 从视频缓冲队列中取出一帧 (DQBUF)
 *   2. 将帧数据映射为 OpenCV Mat 对象
 *   3. 将 YUYV 图像转换为 BGR 图像
 *   4. 将缓冲区重新放回队列 (QBUF)，供驱动继续填充
 */
cv::Mat capture_frame(int vfd, buffer *buffers) {
    /************************************************************
     * Step 1: 从驱动队列中取出一帧图像 (VIDIOC_DQBUF)
     *
     * 原理:
     *   - 驱动采集到视频帧后会将数据放入队列；
     *   - 用户通过 DQBUF (DeQueue Buffer) 取出可用帧；
     *   - 此时返回的 buf.index 指示当前使用的缓冲区编号。
     ************************************************************/
    struct v4l2_buffer buf = {};
    buf.type = V4L2_BUF_TYPE_VIDEO_CAPTURE;
    buf.memory = V4L2_MEMORY_MMAP;
    ioctl(vfd, VIDIOC_DQBUF, &buf);  // 出队 (取出一帧)

    /************************************************************
     * Step 2: 将YUYV帧数据封装为OpenCV的Mat对象
     *
     * OpenCV的Mat构造函数:
     *   Mat(rows, cols, type, data_pointer)
     *
     * 参数解释:
     *   HEIGHT → 行数
     *   WIDTH  → 列数
     *   CV_8UC2 → 每个像素2字节 (YUYV格式: Y1 U Y2 V)
     *   buffers[buf.index].start → 实际帧数据指针
     ************************************************************/
    cv::Mat yuyv(HEIGHT, WIDTH, CV_8UC2, buffers[buf.index].start);

    /************************************************************
     * Step 3: 颜色空间转换 (YUYV → BGR)
     *
     * 说明:
     *   - OpenCV 默认使用 BGR 通道顺序；
     *   - YUYV 是YUV 4:2:2格式，每两个像素共享U、V分量；
     *   - cv::COLOR_YUV2BGR_YUYV 自动进行像素级转换。
     ************************************************************/
    cv::Mat bgr;
    cv::cvtColor(yuyv, bgr, cv::COLOR_YUV2BGR_YUYV);

    /************************************************************
     * Step 4: 将缓冲区重新入队 (VIDIOC_QBUF)
     *
     * 目的:
     *   - 告诉驱动该缓冲区已处理完毕；
     *   - 驱动可以重新填充下一帧图像数据。
     ************************************************************/
    ioctl(vfd, VIDIOC_QBUF, &buf);  // 入队 (重新使用此缓冲区)

    /************************************************************
     * Step 5: 返回转换后的 BGR 图像
     *
     * 注意:
     *   - Mat bgr 是独立拷贝的数据，不依赖内核缓冲；
     *   - 可安全在函数外使用。
     ************************************************************/
    return bgr;
}

/**
 * 函数名: init_serial_115200
 * 功能: 初始化指定串口设备为 115200 波特率通信模式，用于发送双目测距结果。
 *
 * 应用场景:
 *   - 用于与下位机（如 MCU、STM32、或其他传感模块）进行串口通信；
 *   - 例如: 将瞳孔三维坐标 (X, Y, Z) 通过 UART 发送给控制模块或上位机。
 *
 * 参数:
 *   device - 串口设备路径，例如 "/dev/ttyS3" 或 "/dev/ttyUSB0"
 *
 * 返回值:
 *   成功返回串口文件描述符 fd；
 *   打开失败返回 -1。
 *
 * 串口配置说明:
 *   - 波特率: 115200 bps（标准高速通信速率）
 *   - 数据位: 默认 8 位 (CS8)
 *   - 校验位: 无校验 (N)
 *   - 停止位: 1 位
 *   - 控制模式: 原始模式 (Raw Mode)，不进行行缓冲或回显
 */
int init_serial_115200(const char* device) {

    /************************************************************
     * Step 1: 打开串口设备文件
     *
     * O_RDWR   → 可读写；
     * O_NOCTTY → 不将此设备设置为控制终端；
     * 打开成功后返回文件描述符 fd。
     ************************************************************/
    int fd = open(device, O_RDWR | O_NOCTTY);
    if (fd < 0) {
        perror("open serial failed");
        return -1;  // 打开失败返回 -1
    }

    /************************************************************
     * Step 2: 获取当前串口配置
     *
     * termios 结构体:
     *   - 用于保存和设置串口控制参数；
     *   - 包含波特率、数据位、停止位、校验方式等。
     ************************************************************/
    struct termios options;
    tcgetattr(fd, &options);  // 获取当前配置

    /************************************************************
     * Step 3: 设置波特率 (115200)
     *
     * cfsetispeed() → 设置输入速度；
     * cfsetospeed() → 设置输出速度；
     * B115200 → POSIX 宏，代表 115200 bits/s。
     ************************************************************/
    cfsetispeed(&options, B115200);
    cfsetospeed(&options, B115200);

    /************************************************************
     * Step 4: 应用新的串口配置
     *
     * TCSANOW:
     *   - 立即生效；
     *   - 不等待输出缓冲区清空。
     *
     * 注意:
     *   此处未修改其他参数（如数据位、校验位、停止位），
     *   采用系统默认配置（通常为 8N1）。
     ************************************************************/
    tcsetattr(fd, TCSANOW, &options);

    /************************************************************
     * Step 5: 返回串口文件描述符
     *
     * 后续可通过 write(fd, buf, len) 发送数据，
     * 或 read(fd, buf, len) 接收数据。
     ************************************************************/
    return fd;
}

/**
 * 函数名: main
 * 功能: 系统主程序入口，负责整体任务调度与模块协作。
 *
 * 功能概述:
 *   - 初始化线程、串口与双摄像头；
 *   - 实时采集左右相机图像；
 *   - 调用瞳孔检测算法检测左右瞳孔中心；
 *   - 通过三角测量计算三维坐标；
 *   - 结果经串口 (/dev/ttyS3) 实时输出；
 *   - 按下按键 (/dev/input/event1) 时安全退出。
 *
 * 系统流程:
 *   ┌──────────────────────────────────────────────┐
 *   │  1. 启动按键监听线程 (monitor_key_event)     │
 *   │  2. 打开串口 /dev/ttyS3 (115200bps)          │
 *   │  3. 初始化双摄像头 /dev/video21 和 /dev/video23 │
 *   │  4. 主循环中采集图像 → 检测瞳孔 → 三角测量 → 串口输出 │
 *   │  5. 按键触发时 g_running=false → 退出循环     │
 *   │  6. 关闭串口并回收线程                       │
 *   └──────────────────────────────────────────────┘
 */
int main() {

    /************************************************************
     * Step 1: 启动按键监听线程
     *
     * monitor_key_event():
     *   - 独立线程，监听 /dev/input/event1；
     *   - 检测到按键按下时，将 g_running 置为 false；
     *   - 通知主线程安全退出循环。
     ************************************************************/
    std::thread key_thread(monitor_key_event);

    /************************************************************
     * Step 2: 初始化串口通信 (/dev/ttyS3)
     *
     * 波特率: 115200；
     * 作用:
     *   - 通过 UART 将三维坐标结果发送给下位机；
     *   - 例如 STM32、Arduino 或 PC 程序。
     ************************************************************/
    int serial_fd = init_serial_115200("/dev/ttyS3");
    if (serial_fd < 0) return -1;  // 打开失败直接退出

    /************************************************************
     * Step 3: 初始化双摄像头
     *
     * /dev/video21 → 左相机；
     * /dev/video23 → 右相机；
     * 每个摄像头申请 2 个缓冲区用于连续采集。
     ************************************************************/
    int vfd1, vfd2;
    buffer buffers1[2], buffers2[2];
    init_camera("/dev/video21", buffers1, vfd1);
    init_camera("/dev/video23", buffers2, vfd2);

    /************************************************************
     * Step 4: 主循环 — 图像采集与处理
     *
     * 循环条件:
     *   - g_running == true；
     *   - 若按键线程检测到退出信号则终止。
     ************************************************************/
    while (g_running) {
        /****************************************************
         * (1) 从左右相机采集一帧图像
         * capture_frame():
         *   - 从驱动缓冲队列取出一帧；
         *   - 转换为 OpenCV Mat (BGR格式)；
         ****************************************************/
        cv::Mat frame1 = capture_frame(vfd1, buffers1);
        cv::Mat frame2 = capture_frame(vfd2, buffers2);

        /****************************************************
         * (2) 瞳孔检测
         * detect_pupil():
         *   - 灰度化 + 二值化 + 轮廓提取；
         *   - 选择最接近图像中心的圆形区域；
         *   - 返回瞳孔中心坐标。
         ****************************************************/
        cv::Point pt1 = detect_pupil(frame1);
        cv::Point pt2 = detect_pupil(frame2);

        /****************************************************
         * (3) 三角测量计算三维坐标
         * triangulate():
         *   - 使用双目相机参数 (R, T, K1, K2)；
         *   - 通过光线最近点算法求出 (X, Y, Z)；
         *   - 若两个摄像头都检测到瞳孔则执行。
         ****************************************************/
        if (pt1.x >= 0 && pt2.x >= 0) {
            cv::Point3f pos = triangulate(pt1, pt2);

            /************************************************
             * (4) 串口输出结果
             * 格式: "X,Y,Z\n"
             * 单位: 与标定平移向量 T 一致 (通常为 mm)
             ************************************************/
            char buf[64];
            int len = snprintf(buf, sizeof(buf), "%.2f,%.2f,%.2f\n",
                               pos.x, pos.y, pos.z);

            printf("%.2f, %.2f, %.2f\n", pos.x, pos.y, pos.z);
            write(serial_fd, buf, len);  // 串口发送
        }

        /****************************************************
         * (5) 帧率控制
         * 每帧延时约 10 ms ≈ 100 FPS
         * 根据硬件性能可调节延时以平衡实时性与稳定性。
         ****************************************************/
        std::this_thread::sleep_for(std::chrono::milliseconds(10));
    }

    /************************************************************
     * Step 5: 退出清理
     *
     * - 关闭串口；
     * - 等待按键线程结束；
     * - 释放资源。
     ************************************************************/
    close(serial_fd);
    key_thread.join();  // 等待按键监听线程安全退出
    return 0;
}
